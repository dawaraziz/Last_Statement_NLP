{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import fastText\n",
    "import spacy \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find proper datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = open(\"embeddings/glove.6B.100d.txt\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for sent in doc_text:\n",
    "    words = sent.strip().split(\" \")\n",
    "    corpus += words\n",
    "    \n",
    "corpus = set(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = {}\n",
    "\n",
    "for line in glove_model:\n",
    "    split = line.strip().split(\" \")\n",
    "    word = split[0].lower()\n",
    "    vec = split[1:]\n",
    "\n",
    "    if word in corpus:\n",
    "        word_embedding[word] = np.array([float(num) for num in vec])\n",
    "        \n",
    "word_embedding[\"UNKNOWN_TOKEN\"] = np.random.uniform(-0.25, 0.25, len(split)-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = []\n",
    "unknow_tokens = []\n",
    "for sent in doc_text:\n",
    "    words = sent.strip().split(\" \")\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in word_embedding:\n",
    "            vectors.append(word_embedding[word])\n",
    "        else:\n",
    "            vectors.append(word_embedding[\"UNKNOWN_TOKEN\"])\n",
    "            unknow_tokens.append(word)\n",
    "    vectors = np.array(vectors)\n",
    "    glove_embedding.append(np.mean(vectors, axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_embedding = []\n",
    "\n",
    "for sent in doc_text:\n",
    "    spacy_embedding.append(nlp(sent).vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fastText.load_model('embedding/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embedding = []\n",
    "\n",
    "for sent in doc_text:\n",
    "    ft_embedding.append(ft_model.get_sentence_vector(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "use_model = hub.Module(use_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    use_embedding = session.run(use_model(doc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_url = \"https://tfhub.dev/google/elmo/2\"\n",
    "elmo_model = hub.Module(elmo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    elmo_embedding = session.run(use_model(doc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = glove_embedding\n",
    "# embedding = spacy_embedding\n",
    "# embedding = ft_embedding\n",
    "# embedding = use_embedding\n",
    "# embedding = elmo_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "maximum = 16\n",
    "\n",
    "plt.plot()\n",
    "distortions = []\n",
    "K = range(2, maximum+1)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=2018)\n",
    "    kmeans.fit(embedding)\n",
    "    distortions.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=k, init='k-means++', random_state=2018).fit(embedding)\n",
    "clusters = kmeans.predict(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(embedding)\n",
    "tsne = TSNE(n_components=2, random_state=512)\n",
    "reduced = tsne.fit_transform(arr)       \n",
    "t = np.array(reduced).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "markers = [\"x\", \"v\", \"o\", \"s\", \"*\", \">\", \"<\", \"P\", \n",
    "           '1', '2', '3', '4', 'h', \"d\", \"|\", \"+\"]\n",
    "colors = ['darkorange', 'steelblue', 'limegreen',  'salmon', 'y',  'violet', 'c', 'tomato', \n",
    "          'rosybrown', 'brown', 'darkmagenta', 'pink', 'gold', \"orange\", \"skyblue\", \"seagreen\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "for x, y, c in zip(t[0], t[1], clusters):\n",
    "    ax.scatter(x, y, c=colors[c], marker=markers[c])\n",
    "\n",
    "types = []\n",
    "for c in set(clusters):\n",
    "    types.append(Line2D([], [], color=colors[c], marker=markers[c], label=c))\n",
    "\n",
    "plt.legend(handles=types, loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
